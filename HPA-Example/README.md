# Horizontal Pod Autoscaler (HPA) ‚Äî Practical Guide (README)

This section documents how to configure and use **Kubernetes Horizontal Pod Autoscaler (HPA)** using a clear, production-aligned example. It is written to be used directly as a **GitHub README.md** for learning, labs, and internal platform documentation.

---

## üìå What is HPA?

**Horizontal Pod Autoscaler (HPA)** automatically scales the number of pod replicas in a Deployment, ReplicaSet, or StatefulSet based on observed metrics.

Most commonly used metrics:
- CPU utilization
- Memory utilization
- Custom / external metrics (advanced)

‚ö†Ô∏è HPA **requires Metrics Server** to be installed and healthy.

---

## üß± HPA Architecture Overview

```
User Traffic
     ‚Üì
Service
     ‚Üì
Deployment  ‚Üê‚îÄ‚îÄ HPA Controller
     ‚Üì               ‚Üë
Pods  ‚Üê‚îÄ‚îÄ Metrics Server ‚Üê‚îÄ‚îÄ Kubelet
```

---

## ‚úÖ Prerequisites

Before using HPA, verify metrics availability:

```bash
kubectl top nodes
kubectl top pods
```

If both commands return metrics, HPA is ready to use.

---

## üöÄ Example: CPU-based HPA (Recommended Start)

This example demonstrates automatic scaling of an **NGINX Deployment** based on CPU utilization.

---

## 1Ô∏è‚É£ Create Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-hpa-demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx-hpa
  template:
    metadata:
      labels:
        app: nginx-hpa
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "200m"
            memory: "256Mi"
```

Apply:

```bash
kubectl apply -f deployment.yaml
```

‚ö†Ô∏è **CPU requests are mandatory for HPA**

---

## 2Ô∏è‚É£ Create Service

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-hpa-svc
spec:
  selector:
    app: nginx-hpa
  ports:
  - port: 80
    targetPort: 80
```

Apply:

```bash
kubectl apply -f service.yaml
```

---

## 3Ô∏è‚É£ Create HPA Resource

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-hpa-demo
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

Apply:

```bash
kubectl apply -f hpa.yaml
```

---

## üìä Verify HPA Status

```bash
kubectl get hpa
```

Example output:

```
NAME        REFERENCE                  TARGETS   MINPODS   MAXPODS   REPLICAS
nginx-hpa  Deployment/nginx-hpa-demo  10%/50%   1         5         1
```

---

## üî• Generate Load (Trigger Scaling)

### Option 1: BusyBox Load Generator

```bash
kubectl run -i --tty load-generator --image=busybox -- /bin/sh
```

Inside the pod:

```sh
while true; do wget -q -O- http://nginx-hpa-svc; done
```

---

## üëÄ Observe Auto-Scaling

```bash
kubectl get hpa -w
```

Pods will scale automatically:

```
1 ‚Üí 2 ‚Üí 3 ‚Üí 4
```

Check pods:

```bash
kubectl get pods
```

---

## üìâ Scale Down Behavior

When traffic stops:
- CPU usage decreases
- HPA waits stabilization window
- Pods scale down automatically

This prevents frequent scaling fluctuations.

---

## ‚ùå Common Pitfalls

### Missing CPU Requests

Error:
```
failed to get CPU utilization
```

Fix:
```yaml
resources:
  requests:
    cpu: "100m"
```

---

### Metrics Server Not Available

Symptoms:
- HPA shows `unknown`

Fix:
- Ensure Metrics Server is running and ready

---

## üè≠ Production Best Practices

| Area | Recommendation |
|-----|---------------|
| Metric Type | CPU first, Memory carefully |
| minReplicas | ‚â• 2 |
| maxReplicas | Load-tested |
| Resource Requests | Mandatory |
| Load Testing | Required |
| Monitoring | Prometheus + Alerts |

---

## üß† Key Takeaways

- Metrics Server is mandatory
- CPU-based HPA is the safest starting point
- Always define resource requests
- HPA works best for stateless workloads
- Test scaling behavior before production

---

## üìÑ Documentation Metadata

- **Audience:** DevOps / SRE / Platform Engineers
- **Document Type:** GitHub README
- **Scope:** Kubernetes Horizontal Pod Autoscaler (HPA)

---

## ‚úÖ Summary

This README provides a **clear, reproducible, and production-aware introduction** to Kubernetes HPA using a real, working example that can be directly applied in development and learning environments.

